{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('trainingSet.csv')\n",
    "if 'intercept' not in df_train.columns:\n",
    "    df_train.insert(0, 'intercept', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.sample(random_state = 18, frac = 1)\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "breakpoints = []\n",
    "for i in range(0, df.shape[0] + 1, 520):\n",
    "    breakpoints.append(i)\n",
    "for i in range(len(breakpoints)-1):\n",
    "    dfs.append(df.iloc[breakpoints[i]:breakpoints[i+1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_lr = np.zeros([6, 10])\n",
    "accuracy_svm = np.zeros([6, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if x < 0:\n",
    "        return np.exp(x)/(1 + np.exp(x))\n",
    "    else:\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "eta = 0.01\n",
    "maxite = 500\n",
    "tol = 1e-6\n",
    "lam = 0.01\n",
    "\n",
    "def lr_fit(x,y):\n",
    "    length, width = x.shape\n",
    "    \n",
    "    global w \n",
    "    w = np.zeros(width)\n",
    "    y_hat = np.zeros(length)\n",
    "    nabla = np.zeros(width)\n",
    "    \n",
    "    for ite in range(maxite):\n",
    "# yhat\n",
    "        for i in range(length):\n",
    "            prod = np.dot(w,x[i,:])\n",
    "            y_hat[i] = sigmoid(prod)\n",
    "# nabla\n",
    "        y_sum = y_hat - y\n",
    "        nabla = np.matmul(y_sum, x) \n",
    "        nabla += lam * w\n",
    "# w\n",
    "        w_new = w - eta * nabla\n",
    "        diff = w_new - w\n",
    "        L2 = np.linalg.norm(diff)\n",
    "#         if ite % 10 == 0:\n",
    "#             print(L2)\n",
    "        w = w_new\n",
    "        if L2 < tol:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff(x):\n",
    "    if x >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def lr_predict(x, y):\n",
    "    length, width = x.shape\n",
    "    correct = 0\n",
    "    predict = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        prod = np.dot(w, x[i,:])\n",
    "        prob = sigmoid(prod)\n",
    "        predict[i] = cutoff(prob)\n",
    "        if predict[i] == y[i]: \n",
    "            correct += 1\n",
    "    return correct/length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_svm = 0.5\n",
    "maxite_svm = 500\n",
    "tol_svm = 1e-6\n",
    "lam_svm = 0.01\n",
    "    \n",
    "\n",
    "def svm_fit(x,y):\n",
    "    length, width = x.shape\n",
    "    global w_svm\n",
    "    nabla_svm = np.zeros(width)\n",
    "    w_svm = np.zeros(width)\n",
    "    y_hat_svm = np.zeros(length)\n",
    "    \n",
    "    for i in range(length):\n",
    "        if y[i] < 1:\n",
    "            y[i] = -1\n",
    "    \n",
    "    for ite in range(maxite_svm):\n",
    "        y_hat_svm = np.matmul(w_svm,np.transpose(x)) \n",
    "        \n",
    "        yy = y * y_hat_svm\n",
    "        y_copy = np.zeros(length)\n",
    "        for i in range(length):\n",
    "            if yy[i] < 1:\n",
    "                y_copy[i] = y[i]\n",
    "            else:\n",
    "                y_copy[i] = 0\n",
    "                \n",
    "        nabla_svm = -1/length * np.matmul(y_copy, x)\n",
    "        nabla_svm = lam_svm * w_svm + nabla_svm\n",
    "        w_new = w_svm - eta_svm * nabla_svm \n",
    "        diff = w_new - w_svm\n",
    "        w_svm = w_new\n",
    "        L2 = np.linalg.norm(diff)\n",
    "#         if ite % 10 == 0:\n",
    "#             print(f'{ite} {L2}')\n",
    "        if L2 < tol_svm:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    " \n",
    "    \n",
    "def svm_predict(x,y):\n",
    "    length, width = x.shape\n",
    "    predict = np.zeros(length)\n",
    "    correct = 0\n",
    "    for i in range(length):\n",
    "        if y[i] < 1:\n",
    "            y[i] = -1 \n",
    "        predict[i] = sign(np.dot(w_svm,x[i,:]))\n",
    "        if y[i] == predict[i]:\n",
    "            correct += 1\n",
    "    return correct/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i, j, s 0 0 0.7096153846153846\n",
      "i, j, s 0 1 0.6230769230769231\n",
      "i, j, s 0 2 0.6365384615384615\n",
      "i, j, s 0 3 0.6788461538461539\n",
      "i, j, s 0 4 0.6807692307692308\n",
      "i, j, s 0 5 0.6673076923076923\n",
      "i, j, s 1 0 0.7192307692307692\n",
      "i, j, s 1 1 0.625\n",
      "i, j, s 1 2 0.7038461538461539\n",
      "i, j, s 1 3 0.698076923076923\n",
      "i, j, s 1 4 0.6346153846153846\n",
      "i, j, s 1 5 0.7076923076923077\n",
      "i, j, s 2 0 0.676923076923077\n",
      "i, j, s 2 1 0.6076923076923076\n",
      "i, j, s 2 2 0.6173076923076923\n",
      "i, j, s 2 3 0.6865384615384615\n",
      "i, j, s 2 4 0.675\n",
      "i, j, s 2 5 0.6846153846153846\n",
      "i, j, s 3 0 0.6807692307692308\n",
      "i, j, s 3 1 0.6865384615384615\n",
      "i, j, s 3 2 0.6903846153846154\n",
      "i, j, s 3 3 0.7076923076923077\n",
      "i, j, s 3 4 0.6634615384615384\n",
      "i, j, s 3 5 0.6903846153846154\n",
      "i, j, s 4 0 0.698076923076923\n",
      "i, j, s 4 1 0.6942307692307692\n",
      "i, j, s 4 2 0.7\n",
      "i, j, s 4 3 0.6923076923076923\n",
      "i, j, s 4 4 0.6403846153846153\n",
      "i, j, s 4 5 0.6365384615384615\n",
      "i, j, s 5 0 0.7288461538461538\n",
      "i, j, s 5 1 0.6807692307692308\n",
      "i, j, s 5 2 0.7019230769230769\n",
      "i, j, s 5 3 0.6807692307692308\n",
      "i, j, s 5 4 0.6615384615384615\n",
      "i, j, s 5 5 0.6615384615384615\n",
      "i, j, s 6 0 0.5903846153846154\n",
      "i, j, s 6 1 0.5923076923076923\n",
      "i, j, s 6 2 0.6057692307692307\n",
      "i, j, s 6 3 0.6596153846153846\n",
      "i, j, s 6 4 0.6057692307692307\n",
      "i, j, s 6 5 0.6230769230769231\n",
      "i, j, s 7 0 0.5711538461538461\n",
      "i, j, s 7 1 0.676923076923077\n",
      "i, j, s 7 2 0.65\n",
      "i, j, s 7 3 0.6711538461538461\n",
      "i, j, s 7 4 0.6788461538461539\n",
      "i, j, s 7 5 0.6615384615384615\n",
      "i, j, s 8 0 0.6865384615384615\n",
      "i, j, s 8 1 0.6942307692307692\n",
      "i, j, s 8 2 0.625\n",
      "i, j, s 8 3 0.6884615384615385\n",
      "i, j, s 8 4 0.6365384615384615\n",
      "i, j, s 8 5 0.625\n",
      "i, j, s 9 0 0.5826923076923077\n",
      "i, j, s 9 1 0.6211538461538462\n",
      "i, j, s 9 2 0.6557692307692308\n",
      "i, j, s 9 3 0.6326923076923077\n",
      "i, j, s 9 4 0.6346153846153846\n",
      "i, j, s 9 5 0.65\n"
     ]
    }
   ],
   "source": [
    "t_frac = np.array([0.025, 0.05, 0.075, 0.1, 0.15, 0.2])\n",
    "mode = 1\n",
    "\n",
    "for i in range(10):\n",
    "    test_set = dfs[i]\n",
    "    X_test = test_set.drop(columns = ['decision']).to_numpy()\n",
    "    y_test = test_set['decision'].to_numpy()\n",
    "    S_C = df.drop(test_set.index)\n",
    "    for j in range(len(t_frac)):\n",
    "        train_set = S_C.sample(random_state = 32, frac = t_frac[j])\n",
    "\n",
    "        X_train = train_set.drop(columns = ['decision']).to_numpy()\n",
    "        y_train = train_set['decision'].to_numpy()\n",
    "\n",
    "        if mode == 1:\n",
    "            lr_fit(X_train,y_train)\n",
    "            s = lr_predict(X_test, y_test)\n",
    "            accuracy_lr[j][i] = s\n",
    "        elif mode == 2:\n",
    "            svm_fit(X_train,y_train)\n",
    "            s = svm_predict(X_test, y_test)\n",
    "            accuracy_svm[j][i] = s\n",
    "        print(f'i, j, s {i} {j} {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 2\n",
    "for i in range(10):\n",
    "    test_set = dfs[i]\n",
    "    X_test = test_set.drop(columns = ['decision']).to_numpy()\n",
    "    y_test = test_set['decision'].to_numpy()\n",
    "    S_C = df.drop(test_set.index)\n",
    "    for j in range(len(t_frac)):\n",
    "        train_set = S_C.sample(random_state = 32, frac = t_frac[j])\n",
    "\n",
    "        X_train = train_set.drop(columns = ['decision']).to_numpy()\n",
    "        y_train = train_set['decision'].to_numpy()\n",
    "\n",
    "        if mode == 1:\n",
    "            lr_fit(X_train,y_train)\n",
    "            s = lr_predict(X_test, y_test)\n",
    "            accuracy_lr[j][i] = s\n",
    "        elif mode == 2:\n",
    "            svm_fit(X_train,y_train)\n",
    "            s = svm_predict(X_test, y_test)\n",
    "            accuracy_svm[j][i] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('dating.csv')\n",
    "dataframe = dataframe.iloc[0:6500]\n",
    "df_tem = dataframe.sample(random_state = 25, frac = 0.2)\n",
    "df_5200 = dataframe.drop(df_tem.index)\n",
    "df_5200.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbc = df_5200.sample(random_state = 18, frac = 1)\n",
    "df_nbc.reset_index(drop = True, inplace = True)\n",
    "\n",
    "cols_categorial = ['gender','race','race_o','samerace', 'field', 'decision']\n",
    "\n",
    "cols_continuous = dataframe.columns.difference(cols_categorial, sort=False)\n",
    "\n",
    "cols_spec1 = ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence',\n",
    "       'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests',\n",
    "       'attractive_important', 'sincere_important', 'intelligence_important',\n",
    "       'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "    \n",
    "cols_spec2 = ['age', 'age_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printbin(df, col, binsize):\n",
    "    \n",
    "    binmin = 0\n",
    "    binmax = 10;\n",
    "\n",
    "    if (col in cols_spec1):\n",
    "        filt = df[col] > 1.0\n",
    "        df.loc[filt,col] = 1.0\n",
    "        binmin = 0.0\n",
    "        binmax = 1.0\n",
    "    elif (col in cols_spec2):\n",
    "        filt = df[col] > 58.0\n",
    "        df.loc[filt,col] = 58.0\n",
    "        binmin = 18.0\n",
    "        binmax = 58.0\n",
    "    elif (col == 'interests_correlate'):\n",
    "        binmin = -1.0\n",
    "        binmax = 1.0\n",
    "    else:\n",
    "        filt = df[col] > 10.0\n",
    "        df.loc[filt,col] = 10.0\n",
    "        binmin = 0.0\n",
    "        binmax = 10.0\n",
    "    \n",
    "    if binmax == 0.0:\n",
    "        raise Exception(\"Bin not updated\")\n",
    "           \n",
    "    interval = (binmax - binmin)/binsize\n",
    "    thresholds = np.linspace(binmin, binmax, binsize + 1)\n",
    "    \n",
    "#     print(thresholds)\n",
    "    df[col]= pd.cut(df[col], bins=thresholds, labels = range(binsize), include_lowest = True)\n",
    "\n",
    "     \n",
    "    \n",
    "def discretize(df, binsize):\n",
    "    for x in cols_continuous:\n",
    "        printbin(df, x, binsize)\n",
    "        \n",
    "\n",
    "df_dis = df_nbc.copy()\n",
    "discretize(df_dis, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>field</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>...</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender age age_o  race  race_o  samerace importance_same_race  \\\n",
       "4680       0   0     1     2       4         0                    3   \n",
       "4681       1   1     0     2       2         1                    0   \n",
       "4682       0   1     1     0       1         0                    0   \n",
       "4683       1   0     0     2       2         1                    3   \n",
       "4684       0   0     1     0       2         0                    0   \n",
       "...      ...  ..   ...   ...     ...       ...                  ...   \n",
       "5195       0   0     1     2       3         0                    3   \n",
       "5196       1   1     0     3       0         0                    1   \n",
       "5197       1   1     0     0       0         1                    3   \n",
       "5198       0   1     1     0       0         1                    1   \n",
       "5199       0   2     1     0       2         0                    0   \n",
       "\n",
       "     importance_same_religion  field pref_o_attractive  ... theater movies  \\\n",
       "4680                        0     75                 1  ...       4      4   \n",
       "4681                        0    121                 0  ...       2      2   \n",
       "4682                        0    120                 1  ...       1      3   \n",
       "4683                        3     23                 0  ...       3      3   \n",
       "4684                        0    142                 1  ...       2      3   \n",
       "...                       ...    ...               ...  ...     ...    ...   \n",
       "5195                        3    183                 0  ...       3      3   \n",
       "5196                        3     26                 0  ...       4      4   \n",
       "5197                        0     23                 0  ...       3      4   \n",
       "5198                        0     23                 0  ...       3      3   \n",
       "5199                        1    160                 1  ...       4      4   \n",
       "\n",
       "     concerts music shopping yoga interests_correlate  \\\n",
       "4680        4     4        4    3                   2   \n",
       "4681        2     2        3    0                   3   \n",
       "4682        2     3        3    3                   4   \n",
       "4683        2     3        0    0                   3   \n",
       "4684        1     2        3    1                   1   \n",
       "...       ...   ...      ...  ...                 ...   \n",
       "5195        3     3        3    2                   1   \n",
       "5196        3     3        2    1                   2   \n",
       "5197        3     2        1    2                   4   \n",
       "5198        2     2        3    3                   1   \n",
       "5199        4     4        2    2                   1   \n",
       "\n",
       "     expected_happy_with_sd_people like decision  \n",
       "4680                             0    2        0  \n",
       "4681                             4    3        1  \n",
       "4682                             2    1        0  \n",
       "4683                             1    2        0  \n",
       "4684                             2    3        0  \n",
       "...                            ...  ...      ...  \n",
       "5195                             0    2        0  \n",
       "5196                             2    2        0  \n",
       "5197                             4    2        0  \n",
       "5198                             0    2        0  \n",
       "5199                             3    3        1  \n",
       "\n",
       "[520 rows x 53 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fold = []\n",
    "breakpoints = []\n",
    "for i in range(0, df_dis.shape[0] + 1, 520):\n",
    "    breakpoints.append(i)\n",
    "for i in range(len(breakpoints)-1):\n",
    "    df_fold.append(df_dis.iloc[breakpoints[i]:breakpoints[i+1]])\n",
    "df_fold[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prior(y):\n",
    "    prior[1] = y.sum() / len(y)\n",
    "    prior[0] = 1 - prior[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_prob(x, y):\n",
    "    y1 = y.sum()\n",
    "    y0 = len(y) - y1\n",
    "    \n",
    "    D = np.c_[x,y]\n",
    "    for col in range(x.shape[1]):\n",
    "        max_value = x[:,col].max()\n",
    "        if max_value > 5:\n",
    "            max_value = 209\n",
    "        else:\n",
    "            max_value = 4\n",
    "        for v in range(max_value + 1):\n",
    "            count0 = len(np.where((D[:,col] == v) & (D[:, -1] == 0))[0])\n",
    "            count1 = len(np.where((D[:,col] == v) & (D[:, -1] == 1))[0])\n",
    "#             if col == 0:\n",
    "#                 print(f'count {v} {col} {count0} {count1}')\n",
    "            p = count1 / y1\n",
    "            q = count0 / y0\n",
    "            conditional_prob[(col, v, 0)] = q\n",
    "            conditional_prob[(col, v, 1)] = p\n",
    "\n",
    "            if count0 == 0:\n",
    "                conditional_prob[(col, v, 0)] = 1 / (y0 + max_value + 1)\n",
    "            if count1 == 0:\n",
    "                conditional_prob[(col, v, 1)] = 1 / (y1 + max_value + 1)\n",
    "        \n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbc_fit(X, y):\n",
    "    global prior\n",
    "    global conditional_prob\n",
    "    prior = {}\n",
    "    conditional_prob = {}\n",
    "    compute_prior(y)\n",
    "    compute_conditional_prob(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbc_predict(x, y):\n",
    "    correct = 0\n",
    "    predict = np.zeros(x.shape[0])\n",
    "    for row in range(x.shape[0]):\n",
    "        p0 = 0\n",
    "        p1 = 0\n",
    "        for col in range(x.shape[1]):\n",
    "            value = x[row][col]\n",
    "            p0 += np.log(conditional_prob[col, value, 0])\n",
    "            p1 += np.log(conditional_prob[col, value, 1])\n",
    "        p0 += np.log(prior[0])\n",
    "        p1 += np.log(prior[1])\n",
    "        if p0 >= p1:\n",
    "            predict[row] = 0\n",
    "        else:\n",
    "            predict[row] = 1\n",
    "        if predict[row] == y[row]:\n",
    "            correct += 1\n",
    "    return correct / x.shape[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i, j, s 0 0 0.7096153846153846\n",
      "i, j, s 0 1 0.75\n",
      "i, j, s 0 2 0.7615384615384615\n",
      "i, j, s 0 3 0.7634615384615384\n",
      "i, j, s 0 4 0.7403846153846154\n",
      "i, j, s 0 5 0.7673076923076924\n",
      "i, j, s 1 0 0.675\n",
      "i, j, s 1 1 0.6865384615384615\n",
      "i, j, s 1 2 0.7\n",
      "i, j, s 1 3 0.7384615384615385\n",
      "i, j, s 1 4 0.7211538461538461\n",
      "i, j, s 1 5 0.7307692307692307\n",
      "i, j, s 2 0 0.6807692307692308\n",
      "i, j, s 2 1 0.7038461538461539\n",
      "i, j, s 2 2 0.7076923076923077\n",
      "i, j, s 2 3 0.7288461538461538\n",
      "i, j, s 2 4 0.7269230769230769\n",
      "i, j, s 2 5 0.7230769230769231\n",
      "i, j, s 3 0 0.7288461538461538\n",
      "i, j, s 3 1 0.7288461538461538\n",
      "i, j, s 3 2 0.7423076923076923\n",
      "i, j, s 3 3 0.7365384615384616\n",
      "i, j, s 3 4 0.7538461538461538\n",
      "i, j, s 3 5 0.7673076923076924\n",
      "i, j, s 4 0 0.7192307692307692\n",
      "i, j, s 4 1 0.7346153846153847\n",
      "i, j, s 4 2 0.7346153846153847\n",
      "i, j, s 4 3 0.7365384615384616\n",
      "i, j, s 4 4 0.7557692307692307\n",
      "i, j, s 4 5 0.7596153846153846\n",
      "i, j, s 5 0 0.675\n",
      "i, j, s 5 1 0.6942307692307692\n",
      "i, j, s 5 2 0.7211538461538461\n",
      "i, j, s 5 3 0.7211538461538461\n",
      "i, j, s 5 4 0.7269230769230769\n",
      "i, j, s 5 5 0.7346153846153847\n",
      "i, j, s 6 0 0.6653846153846154\n",
      "i, j, s 6 1 0.6826923076923077\n",
      "i, j, s 6 2 0.7096153846153846\n",
      "i, j, s 6 3 0.7230769230769231\n",
      "i, j, s 6 4 0.7192307692307692\n",
      "i, j, s 6 5 0.7269230769230769\n",
      "i, j, s 7 0 0.7\n",
      "i, j, s 7 1 0.7192307692307692\n",
      "i, j, s 7 2 0.7230769230769231\n",
      "i, j, s 7 3 0.7480769230769231\n",
      "i, j, s 7 4 0.7557692307692307\n",
      "i, j, s 7 5 0.7538461538461538\n",
      "i, j, s 8 0 0.6865384615384615\n",
      "i, j, s 8 1 0.7403846153846154\n",
      "i, j, s 8 2 0.7557692307692307\n",
      "i, j, s 8 3 0.7596153846153846\n",
      "i, j, s 8 4 0.7826923076923077\n",
      "i, j, s 8 5 0.7769230769230769\n",
      "i, j, s 9 0 0.65\n",
      "i, j, s 9 1 0.6865384615384615\n",
      "i, j, s 9 2 0.698076923076923\n",
      "i, j, s 9 3 0.6903846153846154\n",
      "i, j, s 9 4 0.7134615384615385\n",
      "i, j, s 9 5 0.7288461538461538\n"
     ]
    }
   ],
   "source": [
    "accuracy_nbc = np.zeros([6,10])\n",
    "\n",
    "for i in range(10):\n",
    "    test_set = df_fold[i]\n",
    "    X_test = test_set.drop(columns = ['decision']).to_numpy()\n",
    "    y_test = test_set['decision'].to_numpy()\n",
    "    S_C = df_dis.drop(test_set.index)\n",
    "    for j in range(len(t_frac)):\n",
    "        train_set = S_C.sample(random_state = 32, frac = t_frac[j])\n",
    "\n",
    "        X_train = train_set.drop(columns = ['decision']).to_numpy()\n",
    "        y_train = train_set['decision'].to_numpy()\n",
    "\n",
    "        nbc_fit(X_train, y_train)\n",
    "        s = nbc_predict(X_test, y_test)\n",
    "        accuracy_nbc[j][i] = s\n",
    "        print(f'i, j, s {i} {j} {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_lr = np.mean(accuracy_lr, axis = 1)\n",
    "ave_svm = np.mean(accuracy_svm, axis = 1)\n",
    "ave_nbc = np.mean(accuracy_nbc, axis = 1)\n",
    "sterr_lr = np.std(accuracy_lr, axis = 1) / np.sqrt(10)\n",
    "sterr_svm = np.std(accuracy_svm, axis = 1) / np.sqrt(10)\n",
    "sterr_nbc = np.std(accuracy_nbc, axis = 1) / np.sqrt(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.errorbar(t_frac * 0.9 * 5200, ave_lr, yerr=sterr_lr, label='LR')\n",
    "plt.errorbar(t_frac * 0.9 * 5200, ave_svm, yerr=sterr_svm, label='SVM')\n",
    "plt.errorbar(t_frac * 0.9 * 5200, ave_nbc, yerr=sterr_nbc, label='NBC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('accuracy.png', dpi = 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59038462, 0.65384615, 0.52692308, 0.60961538, 0.54807692,\n",
       "        0.57307692, 0.53076923, 0.49038462, 0.51923077, 0.52692308],\n",
       "       [0.55961538, 0.47692308, 0.51538462, 0.55192308, 0.55192308,\n",
       "        0.58846154, 0.55192308, 0.57884615, 0.58846154, 0.575     ],\n",
       "       [0.55      , 0.48653846, 0.58846154, 0.53461538, 0.55192308,\n",
       "        0.575     , 0.55769231, 0.57692308, 0.58846154, 0.56346154],\n",
       "       [0.54423077, 0.51923077, 0.58076923, 0.57307692, 0.55      ,\n",
       "        0.57884615, 0.55576923, 0.55      , 0.58846154, 0.57307692],\n",
       "       [0.56346154, 0.6       , 0.575     , 0.64615385, 0.57692308,\n",
       "        0.58269231, 0.55576923, 0.55961538, 0.55769231, 0.56923077],\n",
       "       [0.58653846, 0.60192308, 0.56538462, 0.56538462, 0.58269231,\n",
       "        0.57307692, 0.55384615, 0.575     , 0.55384615, 0.55576923]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=16.510641783841606, pvalue=1.3859056868458644e-08)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(ave_lr,ave_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
