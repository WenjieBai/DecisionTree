{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>pref_o_intelligence</th>\n",
       "      <th>pref_o_funny</th>\n",
       "      <th>...</th>\n",
       "      <th>theater</th>\n",
       "      <th>movies</th>\n",
       "      <th>concerts</th>\n",
       "      <th>music</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>interests_correlate</th>\n",
       "      <th>expected_happy_with_sd_people</th>\n",
       "      <th>like</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  age_o  samerace  importance_same_race  \\\n",
       "2340       0    0      0         1                     0   \n",
       "2341       1    0      0         1                     1   \n",
       "2342       0    0      0         1                     0   \n",
       "2343       1    0      0         1                     0   \n",
       "2344       0    0      0         0                     0   \n",
       "...      ...  ...    ...       ...                   ...   \n",
       "2595       1    0      0         1                     1   \n",
       "2596       0    0      0         0                     0   \n",
       "2597       1    0      0         0                     0   \n",
       "2598       0    0      0         1                     0   \n",
       "2599       1    0      0         0                     1   \n",
       "\n",
       "      importance_same_religion  pref_o_attractive  pref_o_sincere  \\\n",
       "2340                         1                  0               0   \n",
       "2341                         0                  0               0   \n",
       "2342                         0                  0               0   \n",
       "2343                         0                  0               0   \n",
       "2344                         1                  0               0   \n",
       "...                        ...                ...             ...   \n",
       "2595                         0                  0               0   \n",
       "2596                         0                  0               0   \n",
       "2597                         0                  0               0   \n",
       "2598                         0                  0               0   \n",
       "2599                         1                  0               0   \n",
       "\n",
       "      pref_o_intelligence  pref_o_funny  ...  theater  movies  concerts  \\\n",
       "2340                    0             0  ...        0       0         0   \n",
       "2341                    0             0  ...        1       1         1   \n",
       "2342                    0             0  ...        1       1         1   \n",
       "2343                    0             0  ...        1       1         1   \n",
       "2344                    0             0  ...        1       1         1   \n",
       "...                   ...           ...  ...      ...     ...       ...   \n",
       "2595                    0             0  ...        1       1         1   \n",
       "2596                    0             0  ...        1       1         0   \n",
       "2597                    0             0  ...        1       1         1   \n",
       "2598                    0             0  ...        1       1         1   \n",
       "2599                    0             0  ...        1       1         1   \n",
       "\n",
       "      music  shopping  yoga  interests_correlate  \\\n",
       "2340      1         0     0                    1   \n",
       "2341      1         1     0                    1   \n",
       "2342      1         0     0                    1   \n",
       "2343      1         0     1                    1   \n",
       "2344      1         0     1                    1   \n",
       "...     ...       ...   ...                  ...   \n",
       "2595      0         0     0                    0   \n",
       "2596      0         0     0                    1   \n",
       "2597      1         1     0                    1   \n",
       "2598      1         1     1                    0   \n",
       "2599      1         0     1                    1   \n",
       "\n",
       "      expected_happy_with_sd_people  like  decision  \n",
       "2340                              1     1         1  \n",
       "2341                              1     1         1  \n",
       "2342                              0     1         0  \n",
       "2343                              1     1         1  \n",
       "2344                              0     1         1  \n",
       "...                             ...   ...       ...  \n",
       "2595                              1     1         1  \n",
       "2596                              0     0         0  \n",
       "2597                              0     1         0  \n",
       "2598                              1     1         1  \n",
       "2599                              1     1         0  \n",
       "\n",
       "[260 rows x 50 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('trainingSet.csv')\n",
    "# df_test = pd.read_csv('testSet.csv').to_numpy()\n",
    "\n",
    "df_shuffle = df_train.sample(random_state = 18, frac = 1)\n",
    "df = df_shuffle.sample(random_state = 32, frac = 0.5)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "n_folds = 10\n",
    "df_fold = []\n",
    "breakpoints = []\n",
    "for i in range(0, df.shape[0] + 1, int(df.shape[0] / n_folds)):\n",
    "    breakpoints.append(i)\n",
    "for i in range(len(breakpoints)-1):\n",
    "    df_fold.append(df.iloc[breakpoints[i]:breakpoints[i+1]])\n",
    "df_fold[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=8, max_example = 50):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_example = max_example\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(set(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.sum(y == y_hat)/y.size\n",
    "\n",
    "    def _gini(self, y):\n",
    "        m = y.size\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes_))\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        for idx in range(self.n_features_):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):  # possible split positions\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "    \n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(\n",
    "            gini=self._gini(y),\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "\n",
    "\n",
    "        if (depth <= self.max_depth) and (y.size >= self.max_example):\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "    \n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggingDecisionTree:\n",
    "    def __init__(self, n_trees=10, max_depth_outer=8, max_example = 50):\n",
    "        self.n_trees_ = n_trees\n",
    "        self.max_depth_outer = max_depth_outer\n",
    "        self.max_example = max_example\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        models = []\n",
    "        data = np.c_[X,y]\n",
    "        for i in range(self.n_trees_):\n",
    "            data_sample = data[np.random.choice(X.shape[0], X.shape[0], replace=True), :]\n",
    "            X_s = data_sample[:, :-1]\n",
    "            y_s = data_sample[:, -1]\n",
    "            clf = DecisionTreeClassifier(max_depth = self.max_depth_outer)\n",
    "            clf.fit(X_s, y_s)\n",
    "            models.append(clf)\n",
    "            print(f'model {i} trained')\n",
    "        self.models = models\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_all_models = np.empty([X.shape[0], self.n_trees_])\n",
    "        for i in range(self.n_trees_):\n",
    "            y_all_models[:,i] = self.models[i].predict(X)\n",
    "            \n",
    "        y_hat = np.empty(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            y_hat[i] = self.find_majority(y_all_models[i,:])\n",
    "        return y_hat\n",
    "\n",
    "    def find_majority(self, votes):\n",
    "        vote_count = Counter(votes)\n",
    "        top_two = vote_count.most_common(2)\n",
    "        if len(top_two)>1 and top_two[0][1] == top_two[1][1]:\n",
    "            return 0\n",
    "        return top_two[0][0]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.sum(y == y_hat)/y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    def fit(self, X, y):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class RandomForest:\n",
    "        def __init__(self, n_trees=30, max_depth_outer=8, max_example = 50):\n",
    "        self.n_trees_ = n_trees\n",
    "        self.max_depth_outer = max_depth_outer\n",
    "        self.max_example = max_example\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        models = []\n",
    "        data = np.c_[X,y]\n",
    "        for i in range(self.n_trees_):\n",
    "            data_sample = data[np.random.choice(X.shape[0], X.shape[0], replace=True), :]\n",
    "            X_s = data_sample[:, :-1]\n",
    "            y_s = data_sample[:, -1]\n",
    "            clf = DecisionTreeSampleFeature(max_depth=self.max_depth_outer)\n",
    "            clf.fit(X_s, y_s)\n",
    "            models.append(clf)\n",
    "#             print(f'model {i} trained')\n",
    "        self.models = models\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_all_models = np.empty([X.shape[0], self.n_trees_])\n",
    "        for i in range(self.n_trees_):\n",
    "            y_all_models[:,i] = self.models[i].predict(X)\n",
    "            \n",
    "        y_hat = np.empty(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            y_hat[i] = self.find_majority(y_all_models[i,:])\n",
    "        return y_hat\n",
    "        \n",
    "\n",
    "    def find_majority(self, votes):\n",
    "        vote_count = Counter(votes)\n",
    "        top_two = vote_count.most_common(2)\n",
    "        if len(top_two)>1 and top_two[0][1] == top_two[1][1]:\n",
    "            return 0\n",
    "        return top_two[0][0]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.sum(y == y_hat)/y.size\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class DecisionTreeSampleFeature:\n",
    "    def __init__(self, max_depth=8, max_example = 50):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_example = max_example\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(set(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.sum(y == y_hat)/y.size\n",
    "\n",
    "    def _gini(self, y):\n",
    "        m = y.size\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes_))\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        sample_features = np.random.choice(range(self.n_features_),math.isqrt(self.n_features_), replace=False)\n",
    "        \n",
    "        for idx in sample_features:\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):  # possible split positions\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "    \n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(\n",
    "            gini=self._gini(y),\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "\n",
    "\n",
    "        if (depth <= self.max_depth) and (y.size >= self.max_example):\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "    \n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n",
      "model 0 trained\n",
      "model 1 trained\n",
      "model 2 trained\n",
      "model 3 trained\n",
      "model 4 trained\n",
      "model 5 trained\n",
      "model 6 trained\n",
      "model 7 trained\n",
      "model 8 trained\n",
      "model 9 trained\n"
     ]
    }
   ],
   "source": [
    "d = np.array([3, 5, 7, 9])\n",
    "accuracy = np.empty([3, n_folds, len(d)])\n",
    "\n",
    "# for mode in range(1,4):\n",
    "mode = 2\n",
    "for i in range(n_folds):\n",
    "    test_set = df_fold[i]\n",
    "    X_test = test_set.drop(columns = ['decision']).to_numpy()\n",
    "    y_test = test_set['decision'].to_numpy()\n",
    "\n",
    "    train_set = df.drop(test_set.index)\n",
    "    X_train = train_set.drop(columns = ['decision']).to_numpy()\n",
    "    y_train = train_set['decision'].to_numpy()\n",
    "\n",
    "    for j in range(len(d)):\n",
    "        if mode == 1:\n",
    "            clf = DecisionTreeClassifier(max_depth=j)\n",
    "            clf.fit(X_train,y_train)\n",
    "            s = clf.score(X_test,y_test)\n",
    "            accuracy[mode-1][i][j] = s\n",
    "        elif mode == 2:\n",
    "            clf = BaggingDecisionTree(max_depth_outer=j)\n",
    "            clf.fit(X_train,y_train)\n",
    "            s = clf.score(X_test,y_test)\n",
    "            accuracy[mode-1][i][j] = s\n",
    "        elif mode == 3:\n",
    "            clf = RandomForest(max_depth_outer=j)\n",
    "            clf.fit(X_train,y_train)\n",
    "            s = clf.score(X_test,y_test)\n",
    "            accuracy[mode-1][i][j] = s\n",
    "        else:\n",
    "            print('mode error')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69692308, 0.74153846, 0.73961538, 0.74346154])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave = np.empty([3,len(d)])\n",
    "sterr = np.empty([3,len(d)])\n",
    "\n",
    "for i in range(0,1):    \n",
    "    ave[i,:] = np.mean(accuracy[i], axis = 0)\n",
    "    sterr[i,:] = np.std(accuracy[i], axis = 0) / np.sqrt(10)\n",
    "    \n",
    "ave[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.errorbar(d, ave[0], yerr=sterr[0], label='DT')\n",
    "plt.errorbar(d, ave[1], yerr=sterr[1], label='BT')\n",
    "plt.errorbar(d, ave[2], yerr=sterr[2], label='RT')\n",
    "plt.legend(loc='lower right')\n",
    "# plt.savefig('accuracy.png', dpi = 150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for mode in range(1,4):\n",
    "    print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
